---
title: "Pedro Mendes"
date: 2022-12-26T16:49:35-03:00
draft: false
---

{{< figure class="avatar" src="/avatar.jpg" alt="avatar">}}

<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/devicons/devicon@v2.15.1/devicon.min.css">

<!-- # Pedro Mendes -->
<!---->
<!-- - <i class="fas fa-envelope"></i> pedrohrmendes@proton.me -->
<!-- - <i class="fab fa-github"></i> https://github.com/phrmendes/ -->
<!-- - <i class="fab fa-linkedin"></i> [Pedro Mendes](https://www.linkedin.com/in/pedro-mendes-b9983b13a/) -->

# <i class="fas fa-user"></i> About Me

I have four years' experience in the IT market and one years' experience as an economic analyst, also working with data science. I was also a research assistant in the scientific initiation programme at UFABC, and I am currently enrolled in the 11th period of the Science and Humanities programme and the 8th period of the Economics BA degree's programme. Furthermore, I currently work as a DevOps Engineer at NTT DATA. My interests are time series econometrics, machine learning, Linux systems, automations with ansible and programming in R and Python.

# <i class="fas fa-hammer"></i> Skills

- <i class="fab fa-r-project"></i> R - Advanced
  - Libraries: Tidyverse, Tidymodels, data.table, Shiny, SparkR
- <i class="fab fa-python"></i> Python - Intermediate
  - Libraries: NumPy, SciPy, pandas, scikit-learn, TensorFlow, PyTorch, statsmodels, Keras, SQLAlchemy
  - Frameworks: Flask, FastAPI
- <i class="devicon-ansible-plain"></i> Ansible - Intermediate
- <i class="devicon-apache-plain"></i> Apache Spark - Intermediate
- <i class="devicon-azure-plain"></i> Azure - Intermediate
- <i class="devicon-bash-plain"></i> Shell Script - Intermediate
- <i class="devicon-terraform-plain"></i> Terraform - Intermediate
- <i class="fab fa-docker"></i> Docker - Intermediate
- <i class="fab fa-git"></i> Git - Intermediate
- <i class="fab fa-linux"></i> Linux - Intermediate
- <i class="fas fa-database"></i> SQL and databases (MariaDB, PosgreeSQL) - Intermediate
- <i class="devicon-amazonwebservices-original"></i> AWS - Beginner
- <i class="devicon-apache-plain"></i> Apache Airflow - Beginner
- <i class="devicon-argocd-plain"></i> ArgoCD - Beginner
- <i class="devicon-googlecloud-plain"></i> Google Compute Engine - Beginner
- <i class="devicon-kubernetes-plain"></i> Kubernetes - Beginner
- <i class="devicon-mongodb-plain"></i> MongoDB - Beginner
- <i class="devicon-prometheus-original"></i> Prometheus - Beginner

# <i class="fas fa-graduation-cap"></i> Education

## Federal University of ABC

**BA degree in Economics**

- São Bernardo do Campo, SP
- 2018 – 2023

**BA degree in Sciences and Humanities**

- São Bernardo do Campo, SP
- 2018 – 2022

## Fatec São Caetano do Sul

**Information Security (Unfinished)**

- São Caetano do Sul, SP
- 2015 – 2017

# <i class="fas fa-book"></i> Research

## Scientific Initiation Program (PIC-UFABC)

- CECS – UFABC
- São Bernardo do Campo, SP
- 2020–2021

> I researched exports from the Midwest region of Brazil, as well as the commodity cycle of the 2000s and its relationship to the region's agro-industrial complex. I used data from Comex Stats and carried out analyses using tools such as R and Google BigQuery. My research relied on exploratory data analysis and visualisation to draw conclusions about the period analysed.

# <i class="fas fa-briefcase"></i> Work Expericence

## DevOps / Site Reliability Engineer

- NTT Data
- São Paulo, SP
- 2022 – Now

> I manage CI/CD pipelines with Azure DevOps and monitor the performance of microservices with ArgoCD and New Relic. I am also responsible for building automation tools using Infrastructure as Code (Terraform, Terragrunt, Ansible and Helm) and Python.

## Economic analyst

- Abramge
- São Paulo, SP
- 2022 – 2022

> My main activity was related to data extraction about the private healthcare sector in Brazil. To do this, I created ETL pipelines using R to process a broad amount of data, used exploratory data analysis to produce reports and dashboards for public use. I also managed databases using PostgreeSQL and serverless databases such as SQLite and Apache Arrow. I was also responsible for forecasting relevant variables using time series econometric tools (mainly VAR-related models).

## Economics internship

- Abramge
- São Paulo, SP
- 2021 – 2022

> My internship was related to data extraction about the private healthcare sector in Brazil. To do this, I created ETL pipelines using R to process a broad amount of data, used exploratory data analysis to produce reports and dashboards for public use. I also managed databases using PostgreeSQL and serverless databases such as SQLite and Apache Arrow.

# <i class="fas fa-language"></i> Language Proficiency

|  Language  |              Level               |
| :--------: | :------------------------------: |
| Portuguese |              Native              |
|  English   | Professional working proficiency |
|  Spanish   | Professional working proficiency |
